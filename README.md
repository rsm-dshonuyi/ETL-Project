# ETL Pipeline Project

A production-ready, end-to-end ETL (Extract, Transform, Load) pipeline built with Python and Snowflake for processing purchase order and weather data from multiple sources.

## ğŸ¯ Overview

This project demonstrates a complete ETL solution that:
- **Extracts** data from diverse sources (CSV, XML, PostgreSQL, Snowflake Marketplace)
- **Transforms** purchase orders and weather data with comprehensive data cleaning and enrichment
- **Loads** processed data into Snowflake data warehouse for analytics

## ğŸ“ Project Structure

```
ETL-Project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extractors/          # Data extraction modules
â”‚   â”‚   â”œâ”€â”€ csv_extractor.py
â”‚   â”‚   â”œâ”€â”€ xml_extractor.py
â”‚   â”‚   â”œâ”€â”€ postgres_extractor.py
â”‚   â”‚   â””â”€â”€ snowflake_extractor.py
â”‚   â”œâ”€â”€ transformers/        # Data transformation modules
â”‚   â”‚   â”œâ”€â”€ data_transformer.py
â”‚   â”‚   â”œâ”€â”€ purchase_order_transformer.py
â”‚   â”‚   â””â”€â”€ weather_transformer.py
â”‚   â”œâ”€â”€ loaders/             # Data loading modules
â”‚   â”‚   â””â”€â”€ snowflake_loader.py
â”‚   â””â”€â”€ pipeline.py          # Main orchestration script
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml          # Pipeline configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Source data files
â”‚   â””â”€â”€ processed/           # Processed data output
â”œâ”€â”€ tests/                   # Unit tests
â”œâ”€â”€ requirements.txt
â””â”€â”€ setup.py
```

## ğŸš€ Features

### Data Extraction
- **CSV Extractor**: Batch and chunked reading of CSV files
- **XML Extractor**: XPath-based data extraction from XML sources
- **PostgreSQL Extractor**: SQL query execution with connection pooling
- **Snowflake Marketplace Extractor**: Access to Snowflake shared datasets

### Data Transformation
- Column standardization and renaming
- Data type conversion and validation
- Null handling and deduplication
- Business logic enrichment (fiscal periods, order categories)
- Weather severity classification and seasonal analysis
- Purchase order and weather data correlation

### Data Loading
- Bulk loading with Snowflake's write_pandas
- Merge (upsert) operations for incremental updates
- Stage-based file loading
- Transaction management

## ğŸ› ï¸ Installation

1. Clone the repository:
```bash
git clone https://github.com/rsm-dshonuyi/ETL-Project.git
cd ETL-Project
```

2. Create and activate a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Set up environment variables:
```bash
cp .env.example .env
# Edit .env with your credentials
```

## âš™ï¸ Configuration

Edit `config/config.yaml` to configure:
- Snowflake connection settings
- PostgreSQL connection settings
- Data source paths
- Target table names
- Transformation parameters

## ğŸ“Š Usage

### Run the Complete Pipeline
```bash
python -m src.pipeline
```

### Run Specific Phases
```bash
# Extract only
python -m src.pipeline --extract-only

# Transform only
python -m src.pipeline --transform-only

# Load only
python -m src.pipeline --load-only
```

### Use Custom Configuration
```bash
python -m src.pipeline --config path/to/custom/config.yaml
```

## ğŸ§ª Testing

Run the test suite:
```bash
pytest tests/ -v
```

Run with coverage:
```bash
pytest tests/ --cov=src --cov-report=html
```

## ğŸ“ˆ Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CSV File  â”‚â”€â”€â”€â–ºâ”‚             â”‚    â”‚             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚             â”‚    â”‚             â”‚
â”‚   XML File  â”‚â”€â”€â”€â–ºâ”‚  TRANSFORM  â”‚â”€â”€â”€â–ºâ”‚  SNOWFLAKE  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚             â”‚    â”‚             â”‚
â”‚  PostgreSQL â”‚â”€â”€â”€â–ºâ”‚             â”‚    â”‚             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚             â”‚    â”‚             â”‚
â”‚  Marketplaceâ”‚â”€â”€â”€â–ºâ”‚             â”‚    â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Key Components

### Extractors
Each extractor provides a consistent interface:
```python
from src.extractors import CSVExtractor

extractor = CSVExtractor("data/raw/purchase_orders.csv")
df = extractor.extract()
```

### Transformers
Transformers use method chaining for readability:
```python
from src.transformers import PurchaseOrderTransformer

transformer = PurchaseOrderTransformer(df)
result = (
    transformer
    .standardize_columns()
    .drop_nulls()
    .calculate_totals()
    .categorize_orders()
    .get_result()
)
```

### Loader
The loader handles Snowflake operations:
```python
from src.loaders import SnowflakeLoader

loader = SnowflakeLoader(account, user, password, ...)
loader.load(df, "TARGET_TABLE", if_exists="append")
```

## ğŸ“ License

This project is licensed under the MIT License.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“§ Contact

For questions or support, please open an issue in this repository.
